{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19664c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d03fdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorboard==1.15.0\n",
      "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /DATA/gupta37/.local/lib/python3.7/site-packages (from tensorboard==1.15.0) (1.20.3)\n",
      "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0) (1.29.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorboard==1.15.0) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0) (3.12.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0) (0.9.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0) (47.1.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard==1.15.0) (0.32.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0) (3.2.2)\n",
      "Requirement already satisfied: importlib-metadata in /DATA/gupta37/.local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard==1.15.0) (4.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard==1.15.0) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard==1.15.0) (3.7.4.3)\n",
      "Installing collected packages: tensorboard\n",
      "Successfully installed tensorboard-1.15.0\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/utils/entrypoints.py\", line 60, in get_best_invocation_for_this_pip\n",
      "    os.path.join(binary_prefix, exe_name),\n",
      "  File \"/usr/lib/python3.7/genericpath.py\", line 97, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip'\n",
      "Call stack:\n",
      "  File \"/DATA/gupta37/.local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1395, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1519, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1529, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1591, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 905, in handle\n",
      "    self.emit(record)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='22.3.1'),)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50a16cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /DATA/gupta37/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "\u001b[33m[*] 13608 samples loaded.\u001b[0m\n",
      "\u001b[33m[*] 2237 samples loaded.\u001b[0m\n",
      "\u001b[33m[*] 2237 samples loaded.\u001b[0m\n",
      "Using cache found in /DATA/gupta37/.cache/torch/hub/pytorch_vision_v0.8.0\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 112, in <module>\n",
      "    model = DenseNetBertMMModel(num_class=OUTPUT_SIZE, save_dir=save_dir).to(device)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 852, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 530, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 530, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 530, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 552, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 850, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n"
     ]
    }
   ],
   "source": [
    "!python3 main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "197559a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /DATA/gupta37/.local/lib/python3.7/site-packages (from sentence-transformers) (4.11.3)\n",
      "Requirement already satisfied: tqdm in /DATA/gupta37/.local/lib/python3.7/site-packages (from sentence-transformers) (4.62.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in /DATA/gupta37/.local/lib/python3.7/site-packages (from sentence-transformers) (1.9.1)\n",
      "Requirement already satisfied: torchvision in /DATA/gupta37/.local/lib/python3.7/site-packages (from sentence-transformers) (0.10.1)\n",
      "Requirement already satisfied: numpy in /DATA/gupta37/.local/lib/python3.7/site-packages (from sentence-transformers) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn in /DATA/gupta37/.local/lib/python3.7/site-packages (from sentence-transformers) (1.0.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.5.3)\n",
      "Requirement already satisfied: nltk in /DATA/gupta37/.local/lib/python3.7/site-packages (from sentence-transformers) (3.6.3)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.94)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /DATA/gupta37/.local/lib/python3.7/site-packages (from sentence-transformers) (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /DATA/gupta37/.local/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (5.3.1)\n",
      "Requirement already satisfied: importlib-metadata in /DATA/gupta37/.local/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.12.0)\n",
      "Requirement already satisfied: filelock in /DATA/gupta37/.local/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.7.4.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2020.10.28)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.43)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /DATA/gupta37/.local/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.10.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /DATA/gupta37/.local/lib/python3.7/site-packages (from torchvision->sentence-transformers) (8.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /DATA/gupta37/.local/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2018.8.24)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /DATA/gupta37/.local/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.12.0)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125919 sha256=1a10e3f9c52612422e2cec97b7e04a1b0c5a047f15be3022a74234b6b504d17f\n",
      "  Stored in directory: /DATA/gupta37/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-2.2.2\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/utils/entrypoints.py\", line 60, in get_best_invocation_for_this_pip\n",
      "    os.path.join(binary_prefix, exe_name),\n",
      "  File \"/usr/lib/python3.7/genericpath.py\", line 97, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip'\n",
      "Call stack:\n",
      "  File \"/DATA/gupta37/.local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1395, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1519, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1529, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1591, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 905, in handle\n",
      "    self.emit(record)\n",
      "  File \"/DATA/gupta37/.local/lib/python3.7/site-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='22.3.1'),)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0953bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,4,5,7\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf2b8296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /DATA/gupta37/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "@author: Chonghan Chen <chonghac@cs.cmu.edu>\n",
    "\"\"\"\n",
    "from os import path as osp\n",
    "import os\n",
    "import logging\n",
    "from PIL import Image\n",
    "from torch.serialization import save\n",
    "from args import get_args\n",
    "from trainer import Trainer\n",
    "from crisismmd_dataset import CrisisMMDataset, CrisisMMDatasetWithSSE\n",
    "from mm_models import DenseNetBertMMModel, ImageOnlyModel, TextOnlyModel\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.modules import activation\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import time\n",
    "import argparse\n",
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf1d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "\n",
    "    # -------------- Important configs --------------- #\n",
    "    parser.add_argument('--mode', choices=['both', 'image_only', 'text_only'], default='both')\n",
    "    parser.add_argument('--task', choices=['task1', 'task2', 'task2_merged'], default='task1')\n",
    "    parser.add_argument('--learning_rate', default=2e-3, type=float)\n",
    "    parser.add_argument('--batch_size', default=64, type=int)\n",
    "    parser.add_argument('--save_dir', default='./output', type=str)\n",
    "    parser.add_argument('--model_name', default='', type=str)\n",
    "    parser.add_argument('--consistent_only', action='store_true')\n",
    "\n",
    "    parser.add_argument('--with_sse', action='store_true')\n",
    "\n",
    "    # only used when with_sse set\n",
    "    parser.add_argument('--pv', default=1000, type=int)\n",
    "    parser.add_argument('--pt', default=1000, type=int)\n",
    "    parser.add_argument('--pv0', default=0.3, type=float)\n",
    "    parser.add_argument('--pt0', default=0.7, type=float)\n",
    "\n",
    "    # Loading model \n",
    "    parser.add_argument('--model_to_load', default='')\n",
    "    parser.add_argument('--image_model_to_load', default='')\n",
    "    parser.add_argument('--text_model_to_load', default='')\n",
    "\n",
    "\n",
    "    parser.add_argument('--max_iter', default=5, type=int)\n",
    "\n",
    "    # -------------- Default ones --------------- #\n",
    "    # Running configs\n",
    "\n",
    "    # Run flag\n",
    "    parser.add_argument('--debug', action='store_true')\n",
    "    parser.add_argument('--eval', action='store_true')\n",
    "    parser.add_argument('--use_tensorboard', action='store_true')\n",
    "\n",
    "    # System configs\n",
    "    parser.add_argument('--device', default='cuda')\n",
    "    parser.add_argument('--num_workers', default=0, type=int)\n",
    "\n",
    "\n",
    "    # data processing\n",
    "    parser.add_argument('--load_size', default=228, type=int)\n",
    "    parser.add_argument('--crop_size', default=224, type=int)\n",
    "    parser.add_argument('--max_dataset_size', default=2147483648, type=int)\n",
    "\n",
    "\n",
    "    \n",
    "    return parser.parse_known_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a512b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[*] 13608 samples loaded.\u001b[0m\n",
      "\u001b[33m[*] 2237 samples loaded.\u001b[0m\n",
      "\u001b[33m[*] 2237 samples loaded.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /DATA/gupta37/.cache/torch/hub/pytorch_vision_v0.8.0\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 27%|██▋       | 58/213 [02:20<05:18,  2.05s/it] /DATA/gupta37/.local/lib/python3.7/site-packages/PIL/Image.py:976: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|██████████| 213/213 [07:46<00:00,  2.19s/it]\n",
      "100%|██████████| 213/213 [07:28<00:00,  2.11s/it]\n",
      "100%|██████████| 213/213 [07:28<00:00,  2.11s/it]\n",
      "100%|██████████| 213/213 [07:28<00:00,  2.11s/it]\n",
      "100%|██████████| 213/213 [07:27<00:00,  2.10s/it]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    opt, unkown = get_args()\n",
    "\n",
    "    model_to_load = opt.model_to_load\n",
    "    image_model_to_load = opt.image_model_to_load\n",
    "    text_model_to_load = opt.text_model_to_load\n",
    "\n",
    "    device = opt.device\n",
    "    num_workers = opt.num_workers\n",
    "\n",
    "    EVAL = opt.eval\n",
    "    USE_TENSORBOARD = opt.use_tensorboard\n",
    "    SAVE_DIR = opt.save_dir\n",
    "    MODEL_NAME = opt.model_name if opt.model_name else str(int(time.time()))\n",
    "\n",
    "    MODE = opt.mode\n",
    "    TASK = opt.task\n",
    "    MAX_ITER = opt.max_iter\n",
    "    OUTPUT_SIZE = None \n",
    "    if TASK == 'task1':\n",
    "        OUTPUT_SIZE = 2\n",
    "    elif TASK == 'task2':\n",
    "        OUTPUT_SIZE = 8\n",
    "    elif TASK == 'task2_merged':\n",
    "        OUTPUT_SIZE = 6\n",
    "    else:\n",
    "        raise NotImplemented\n",
    "\n",
    "    # The authors did not report the following values, but they tried\n",
    "    # pv, pt in [10, 20000], and pv0, pt0 in [0, 1]\n",
    "    WITH_SSE = opt.with_sse\n",
    "    pv = opt.pv # How many times more likely do we transit to the same class\n",
    "    pt = opt.pt \n",
    "    pv0 = opt.pv0  # Probability of not doing a transition\n",
    "    pt0 = opt.pt0\n",
    "\n",
    "    # General hyper parameters\n",
    "    learning_rate = opt.learning_rate\n",
    "    batch_size = opt.batch_size\n",
    "\n",
    "    # Create folder for saving\n",
    "    save_dir = osp.join(SAVE_DIR, MODEL_NAME)\n",
    "    if not osp.exists(SAVE_DIR):\n",
    "        os.mkdir(SAVE_DIR)\n",
    "    if not osp.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "\n",
    "\n",
    "    # set logger\n",
    "    logging.basicConfig(filename=osp.join(save_dir, 'output_{}.log'.format(int(time.time()))), level=logging.INFO)\n",
    "\n",
    "\n",
    "    train_loader, dev_loader = None, None\n",
    "    if not EVAL:\n",
    "        if WITH_SSE:\n",
    "            train_set = CrisisMMDatasetWithSSE()\n",
    "            train_set.initialize(opt, pv, pt, pv0, pt0, phase='train', cat='all',\n",
    "                                 task=TASK)\n",
    "        else:\n",
    "            train_set = CrisisMMDataset()\n",
    "            train_set.initialize(opt, phase='train', cat='all',\n",
    "                                 task=TASK)\n",
    "        train_loader = DataLoader(\n",
    "            train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "    dev_set = CrisisMMDataset()\n",
    "    dev_set.initialize(opt, phase='dev', cat='all',\n",
    "                       task=TASK)\n",
    "\n",
    "    dev_loader = DataLoader(\n",
    "        dev_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    test_set = CrisisMMDataset()\n",
    "    test_set.initialize(opt, phase='test', cat='all',\n",
    "                        task=TASK)\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    if MODE == 'text_only':\n",
    "        model = TextOnlyModel(num_class=OUTPUT_SIZE, save_dir=save_dir).to(device)\n",
    "    elif MODE == 'image_only':\n",
    "        model = ImageOnlyModel(num_class=OUTPUT_SIZE, save_dir=save_dir).to(device)\n",
    "    elif MODE == 'both':\n",
    "        model = DenseNetBertMMModel(num_class=OUTPUT_SIZE, save_dir=save_dir).to(device)\n",
    "    else:\n",
    "        raise NotImplemented\n",
    "\n",
    "    model = nn.DataParallel(model)\n",
    "    # The authors did not mention configurations of SGD. We assume they did not use momentum or weight decay.\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # The authors used factor=0.1, but did not mention other configs.\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, factor=0.1, patience=5, cooldown=0, verbose=True)\n",
    "\n",
    "    trainer = Trainer(train_loader, dev_loader, test_loader,\n",
    "                      model, loss_fn, optimizer, scheduler, eval=EVAL, device=device, tensorboard=USE_TENSORBOARD, mode=MODE)\n",
    "\n",
    "    if model_to_load:\n",
    "        model.load(model_to_load)\n",
    "        logging.info(\"\\n***********************\")\n",
    "        logging.info(\"Model Loaded!\")\n",
    "        logging.info(\"***********************\\n\")\n",
    "    if text_model_to_load:\n",
    "        model.load(text_model_to_load)\n",
    "    if image_model_to_load:\n",
    "        model.load(image_model_to_load)\n",
    "\n",
    "    if not EVAL:\n",
    "        logging.info(\"\\n================Training Summary=================\")\n",
    "        logging.info(\"Training Summary: \")\n",
    "        logging.info(\"Learning rate {}\".format(learning_rate))\n",
    "        logging.info(\"Batch size {}\".format(batch_size))\n",
    "        logging.info(trainer.model)\n",
    "        logging.info(\"\\n=================================================\")\n",
    "\n",
    "        trainer.train(MAX_ITER)\n",
    "\n",
    "    else:\n",
    "        logging.info(\"\\n================Evaluating Model=================\")\n",
    "        logging.info(trainer.model)\n",
    "\n",
    "        trainer.validate()\n",
    "        trainer.predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c0f800f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patched image shape: torch.Size([32, 324, 12288])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImagePatcher(torch.nn.Module):\n",
    "    def __init__(self, patch_size, stride):\n",
    "        super(ImagePatcher, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, image):\n",
    "        # Unfold the image into patches\n",
    "        patches = F.unfold(image, self.patch_size, stride=self.stride)\n",
    "        \n",
    "        # Reshape patches to have shape (batch_size, num_patches, patch_dim)\n",
    "        batch_size, patch_dim, num_patches = patches.shape\n",
    "        patches = patches.permute(0, 2, 1).contiguous().view(batch_size, num_patches, patch_dim)\n",
    "        \n",
    "        return patches\n",
    "\n",
    "# Example usage\n",
    "batch_size = 32\n",
    "image_channels = 3\n",
    "image_height = 624\n",
    "image_width = 624\n",
    "patch_size = 64\n",
    "stride = 32\n",
    "\n",
    "# Create a random image\n",
    "input_image = torch.randn(batch_size, image_channels, image_height, image_width)\n",
    "\n",
    "# Initialize the ImagePatcher\n",
    "patcher = ImagePatcher(patch_size, stride)\n",
    "\n",
    "# Extract patches from the image\n",
    "patches = patcher(input_image)\n",
    "\n",
    "print(\"Patched image shape:\", patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0afbfdd3-fbe1-4a0d-ba66-3399bc1b1682",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1200, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor_to_repeat = torch.rand(40, 768)  # Example tensor with size [40, 768]\n",
    "num_repeats = 30\n",
    "\n",
    "# Repeat each row of the tensor along the first dimension and stack them next to the original rows\n",
    "repeated_tensor = tensor_to_repeat.unsqueeze(1).repeat(1, num_repeats, 1).view(-1, 768)\n",
    "\n",
    "print(repeated_tensor.size())  # Output: torch.Size([1200, 768])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5057c878-e761-40dd-87c9-198d050f3ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1440])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensor y with size [40]\n",
    "y = torch.arange(40)  # Replace with your actual tensor\n",
    "\n",
    "num_repeats = 36\n",
    "\n",
    "# Repeat each element of the tensor along the first dimension and stack them in the desired pattern\n",
    "repeated_y = y.unsqueeze(1).repeat(1, num_repeats).view(-1)\n",
    "\n",
    "print(repeated_y.size())  # Output: torch.Size([1440])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6a363db-99b5-4cc8-a641-1f28cad93e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  ..., 39, 39, 39])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeated_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7034b30a-4501-45a6-8bd1-5bff41852871",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8403, 0.4962, 0.4988,  ..., 0.1059, 0.8652, 0.6119])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeated_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73aa9bc3-3d6f-44ba-a1bd-0c584cd72c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1772, 0.0974, 0.3920,  ..., 0.9931, 0.2331, 0.5567],\n",
       "        [0.1772, 0.0974, 0.3920,  ..., 0.9931, 0.2331, 0.5567],\n",
       "        [0.1772, 0.0974, 0.3920,  ..., 0.9931, 0.2331, 0.5567],\n",
       "        ...,\n",
       "        [0.3354, 0.0778, 0.2314,  ..., 0.4546, 0.2189, 0.2337],\n",
       "        [0.3354, 0.0778, 0.2314,  ..., 0.4546, 0.2189, 0.2337],\n",
       "        [0.3354, 0.0778, 0.2314,  ..., 0.4546, 0.2189, 0.2337]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeated_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e767aee2-ac8d-45be-933d-03aa3427d3a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.7104e-01, 6.9419e-01, 4.9610e-01, 3.6986e-02, 4.3606e-01, 1.8935e-01,\n",
       "        6.2840e-02, 4.5809e-01, 7.9554e-01, 5.0419e-01, 6.8246e-01, 2.1839e-01,\n",
       "        5.2679e-01, 7.6919e-01, 1.0877e-01, 7.9852e-01, 9.5645e-02, 2.4431e-01,\n",
       "        6.6142e-01, 1.9574e-01, 3.6641e-01, 1.0533e-01, 9.7603e-01, 1.8963e-01,\n",
       "        7.8898e-01, 9.7901e-01, 8.6092e-01, 5.9248e-01, 8.7987e-01, 1.7068e-01,\n",
       "        2.4865e-01, 5.7405e-01, 3.6602e-01, 5.2501e-02, 8.1018e-01, 6.3171e-01,\n",
       "        9.4364e-01, 4.0154e-02, 5.3145e-01, 7.9944e-02, 7.9464e-01, 9.7079e-01,\n",
       "        1.1360e-01, 7.2285e-01, 5.9192e-02, 8.7586e-01, 3.7283e-01, 6.8294e-01,\n",
       "        6.8903e-01, 6.1682e-01, 4.2660e-01, 5.5722e-02, 3.3103e-01, 3.8915e-01,\n",
       "        2.1087e-01, 6.5777e-01, 3.7294e-03, 7.3661e-01, 9.7451e-01, 9.3866e-01,\n",
       "        3.4468e-01, 1.3064e-01, 2.8299e-01, 2.4630e-01, 7.1969e-01, 6.1637e-01,\n",
       "        9.7601e-01, 4.8285e-01, 3.0111e-02, 1.6904e-01, 7.2407e-02, 8.8599e-01,\n",
       "        5.0038e-01, 3.8339e-01, 9.3117e-01, 2.3139e-01, 4.2047e-01, 6.9000e-01,\n",
       "        4.9567e-01, 5.0084e-01, 9.1938e-01, 1.9901e-01, 5.4140e-01, 9.5079e-01,\n",
       "        3.8607e-01, 7.2774e-02, 6.0725e-01, 1.7138e-01, 3.6416e-01, 4.7136e-01,\n",
       "        9.8419e-01, 3.7204e-01, 5.9387e-01, 6.5948e-01, 9.7986e-01, 6.1372e-02,\n",
       "        3.2072e-02, 7.6789e-01, 5.0634e-04, 5.4488e-01, 9.3046e-01, 4.6474e-01,\n",
       "        7.1329e-01, 7.7778e-01, 9.9988e-01, 3.2363e-01, 8.3387e-01, 6.1144e-01,\n",
       "        7.0894e-01, 4.1318e-01, 6.0624e-01, 7.2854e-01, 2.9107e-01, 3.9734e-01,\n",
       "        4.1401e-01, 9.4321e-01, 1.2578e-01, 5.2429e-01, 1.9141e-01, 6.6801e-02,\n",
       "        6.2667e-01, 4.5237e-01, 8.9157e-01, 9.3501e-01, 1.9293e-01, 1.9271e-01,\n",
       "        6.0304e-01, 5.5139e-01, 1.6201e-01, 6.0055e-01, 9.5248e-01, 8.9726e-01,\n",
       "        8.2106e-01, 1.5502e-02, 7.6297e-01, 9.5468e-01, 9.9275e-01, 2.9494e-02,\n",
       "        3.0736e-01, 3.3327e-01, 9.7304e-01, 5.2162e-01, 2.3031e-01, 3.6164e-01,\n",
       "        8.0026e-01, 7.5804e-01, 7.5614e-01, 8.2025e-02, 5.0995e-01, 2.5876e-03,\n",
       "        7.9716e-01, 9.1769e-01, 6.6754e-01, 3.1811e-01, 9.4247e-02, 7.0216e-01,\n",
       "        5.6377e-01, 2.7489e-01, 1.1155e-01, 9.1182e-01, 7.3036e-01, 9.8403e-01,\n",
       "        3.0640e-02, 8.1954e-01, 6.3943e-01, 8.1690e-01, 4.5570e-01, 7.2233e-01,\n",
       "        6.6948e-01, 5.3331e-02, 7.8047e-01, 7.2018e-01, 5.8616e-01, 3.7356e-01,\n",
       "        1.0571e-01, 7.5295e-01, 4.8665e-01, 7.2028e-02, 8.0440e-01, 2.6119e-01,\n",
       "        9.3487e-01, 8.4159e-01, 4.5070e-01, 1.3687e-01, 2.4325e-01, 5.3234e-02,\n",
       "        3.7554e-01, 5.2356e-01, 4.3788e-01, 9.3362e-01, 4.9659e-02, 6.1983e-01,\n",
       "        4.8343e-01, 4.6825e-02, 1.4471e-02, 1.7301e-01, 5.2262e-01, 8.7398e-01,\n",
       "        7.1341e-02, 8.1168e-01, 9.8784e-01, 7.1871e-01, 4.2821e-01, 7.4193e-01,\n",
       "        9.4343e-02, 7.4603e-02, 8.0972e-01, 4.8838e-01, 1.6289e-02, 3.6706e-01,\n",
       "        1.6074e-01, 6.6281e-01, 8.7612e-01, 5.0881e-01, 8.9749e-01, 8.3342e-01,\n",
       "        3.2186e-01, 9.5670e-01, 6.3179e-01, 3.0222e-01, 1.4483e-01, 9.9853e-01,\n",
       "        5.3913e-01, 8.9641e-01, 7.6415e-01, 8.0245e-01, 8.8340e-02, 6.0700e-01,\n",
       "        4.9674e-01, 5.2658e-02, 7.7606e-01, 6.1685e-01, 2.0563e-01, 4.5327e-01,\n",
       "        7.0078e-01, 2.0426e-01, 5.3504e-02, 4.2369e-01, 7.8729e-01, 6.0237e-01,\n",
       "        1.8549e-01, 6.0497e-01, 6.5596e-01, 7.1118e-01, 8.1335e-01, 9.0817e-01,\n",
       "        3.7626e-01, 5.2518e-01, 2.3606e-01, 5.7162e-01, 3.8227e-01, 2.5426e-01,\n",
       "        2.1611e-01, 4.0531e-01, 3.6850e-01, 9.2478e-01, 9.6260e-01, 4.0848e-01,\n",
       "        5.9010e-01, 9.3225e-01, 5.1251e-02, 4.3263e-01, 8.8496e-01, 2.3832e-03,\n",
       "        6.6569e-01, 5.1565e-02, 6.6986e-01, 9.3213e-01, 6.6962e-01, 4.4316e-02,\n",
       "        3.9090e-03, 2.5259e-01, 7.9498e-01, 3.9818e-01, 7.1668e-01, 3.3510e-01,\n",
       "        5.5756e-01, 8.3969e-01, 7.7392e-01, 8.7694e-01, 6.0253e-01, 2.5370e-01,\n",
       "        8.7296e-01, 3.9149e-01, 9.4034e-01, 8.0129e-01, 9.5216e-01, 1.9601e-01,\n",
       "        8.4665e-01, 9.0108e-01, 9.5108e-01, 5.2108e-01, 3.9366e-01, 4.4924e-01,\n",
       "        8.8568e-01, 7.8231e-01, 7.0381e-01, 6.8123e-01, 2.7896e-01, 9.0936e-01,\n",
       "        7.9995e-01, 1.0821e-01, 3.1461e-01, 1.3574e-01, 2.2364e-01, 8.2271e-02,\n",
       "        2.9579e-01, 8.6528e-01, 6.9755e-01, 9.7287e-01, 3.6123e-01, 3.4618e-01,\n",
       "        4.8752e-01, 7.9588e-02, 4.4998e-01, 9.6131e-01, 7.6484e-01, 9.1028e-01,\n",
       "        2.1476e-02, 3.0383e-01, 1.9402e-01, 6.8782e-01, 1.9358e-01, 8.1509e-01,\n",
       "        4.5360e-01, 6.5342e-01, 7.9596e-01, 1.3974e-01, 2.3203e-01, 5.9821e-01,\n",
       "        5.2779e-01, 6.2698e-01, 7.0119e-01, 6.8193e-01, 8.4881e-02, 1.0436e-01,\n",
       "        9.2293e-01, 6.0660e-01, 8.2098e-01, 5.2393e-01, 3.6357e-01, 1.5978e-01,\n",
       "        9.9438e-02, 9.1190e-01, 9.5793e-01, 2.8442e-01, 4.5029e-01, 4.0369e-01,\n",
       "        2.7342e-01, 3.9191e-01, 1.9599e-01, 2.7703e-01, 2.6610e-01, 3.7077e-01,\n",
       "        1.6842e-01, 8.0059e-01, 7.3927e-01, 5.8084e-01, 2.5155e-01, 8.6007e-01,\n",
       "        5.3723e-01, 3.5680e-02, 6.7567e-01, 1.6519e-02, 4.3196e-01, 4.8881e-01,\n",
       "        3.5947e-01, 1.3662e-01, 2.3663e-01, 6.1435e-01, 4.2682e-02, 1.4511e-01,\n",
       "        5.3029e-01, 8.7452e-01, 1.5159e-01, 6.4468e-01, 8.9927e-01, 3.2226e-01,\n",
       "        2.8162e-01, 3.8479e-02, 2.6124e-01, 3.0537e-01, 6.0488e-01, 4.7798e-01,\n",
       "        5.9450e-01, 1.8014e-01, 4.9171e-01, 9.6444e-01, 4.9446e-01, 9.3066e-01,\n",
       "        1.7234e-02, 4.9790e-01, 7.3409e-01, 4.8722e-02, 3.3392e-01, 4.8507e-01,\n",
       "        3.9349e-01, 1.8553e-01, 4.1829e-01, 9.6457e-01, 7.3183e-01, 9.6452e-01,\n",
       "        6.7231e-01, 2.2439e-01, 2.2288e-02, 6.0774e-01, 4.0907e-01, 1.5984e-01,\n",
       "        6.5840e-01, 7.4785e-01, 6.3767e-01, 2.5861e-03, 3.8341e-01, 4.5025e-01,\n",
       "        8.7051e-01, 8.0581e-01, 1.6467e-01, 3.2152e-01, 8.0409e-01, 7.2118e-01,\n",
       "        5.0777e-01, 4.2187e-01, 8.8402e-01, 5.3517e-01, 2.6469e-01, 3.9689e-01,\n",
       "        3.2808e-02, 6.8855e-01, 9.4782e-01, 3.2486e-01, 9.6620e-01, 4.0408e-01,\n",
       "        1.2930e-01, 8.6374e-01, 4.3745e-01, 2.0142e-01, 2.1156e-01, 5.8882e-01,\n",
       "        1.7408e-01, 1.8432e-01, 5.5689e-01, 2.2968e-01, 2.0654e-01, 5.1343e-01,\n",
       "        2.6559e-01, 2.0743e-01, 3.5956e-01, 6.1051e-02, 5.7018e-01, 3.6939e-01,\n",
       "        8.6586e-01, 4.7295e-01, 7.7503e-01, 3.6716e-01, 1.5702e-01, 8.5067e-01,\n",
       "        6.6709e-01, 4.0307e-01, 3.8008e-01, 8.2650e-01, 6.1472e-01, 2.6945e-01,\n",
       "        4.7575e-01, 8.3527e-01, 8.8032e-01, 2.6462e-01, 8.1376e-01, 8.1713e-01,\n",
       "        6.6555e-01, 7.2850e-01, 7.8365e-01, 8.7031e-01, 7.0223e-01, 9.0017e-02,\n",
       "        1.1477e-01, 2.9087e-01, 1.8578e-01, 2.1364e-01, 9.9512e-01, 4.0160e-01,\n",
       "        6.3217e-01, 2.0132e-01, 6.3557e-01, 2.7555e-01, 3.6769e-01, 5.9180e-01,\n",
       "        1.1411e-01, 9.3458e-01, 4.8624e-01, 6.1665e-01, 6.2729e-01, 9.5743e-01,\n",
       "        6.2210e-01, 3.0607e-01, 6.4609e-01, 9.8179e-01, 6.6366e-01, 8.2257e-01,\n",
       "        3.1266e-01, 4.0861e-01, 2.1295e-01, 3.5031e-01, 5.7307e-01, 4.5268e-01,\n",
       "        1.0887e-02, 7.3238e-01, 2.5405e-01, 6.3016e-01, 4.1364e-01, 6.7950e-01,\n",
       "        6.0695e-02, 9.9463e-01, 1.7865e-01, 6.4879e-01, 1.8618e-01, 4.2094e-01,\n",
       "        5.7069e-01, 5.0697e-01, 1.9651e-01, 9.4942e-01, 9.3123e-01, 8.8703e-02,\n",
       "        5.2287e-02, 2.5218e-01, 2.3821e-01, 7.3356e-01, 1.1553e-01, 6.0768e-01,\n",
       "        7.8700e-01, 7.7445e-01, 2.8338e-01, 7.4181e-01, 5.4903e-01, 7.1624e-01,\n",
       "        9.0665e-01, 9.9100e-01, 2.3323e-01, 5.6655e-01, 7.4805e-01, 7.9375e-01,\n",
       "        1.9231e-01, 5.9030e-01, 2.7953e-01, 5.6448e-02, 3.1857e-01, 1.6334e-01,\n",
       "        8.3215e-01, 6.4059e-01, 6.8618e-02, 1.6195e-01, 9.4308e-01, 5.3074e-01,\n",
       "        1.2210e-01, 1.0389e-01, 9.8795e-01, 9.9293e-01, 9.7286e-01, 3.0689e-01,\n",
       "        2.5247e-02, 8.2469e-01, 5.5138e-01, 7.9257e-01, 2.0322e-01, 1.5003e-01,\n",
       "        5.9460e-02, 7.6806e-02, 4.8215e-02, 2.9328e-01, 6.0579e-01, 2.1298e-01,\n",
       "        4.5271e-01, 8.5176e-02, 6.8754e-01, 7.8165e-01, 7.7068e-01, 4.5051e-01,\n",
       "        7.1235e-01, 8.6011e-01, 3.8640e-01, 3.9602e-01, 5.9547e-02, 6.6710e-01,\n",
       "        7.8293e-01, 1.6027e-01, 8.9045e-01, 3.2141e-01, 6.3868e-01, 9.8408e-01,\n",
       "        4.6123e-01, 5.9084e-01, 7.1332e-01, 1.6708e-01, 9.6388e-01, 5.7983e-01,\n",
       "        4.0858e-01, 2.7150e-01, 4.4458e-01, 8.5706e-01, 9.0590e-01, 2.7807e-01,\n",
       "        4.5789e-01, 1.2018e-02, 2.8828e-01, 9.0115e-01, 9.6758e-01, 2.3848e-01,\n",
       "        3.2215e-01, 7.3016e-01, 9.5975e-01, 5.4114e-01, 7.3932e-01, 4.2953e-01,\n",
       "        3.6485e-01, 7.8158e-02, 4.7069e-01, 2.8323e-01, 7.5139e-01, 2.4686e-01,\n",
       "        7.8865e-01, 4.2994e-01, 6.7236e-01, 3.6543e-01, 2.2424e-01, 5.8938e-01,\n",
       "        2.4517e-01, 4.2455e-01, 9.2981e-01, 7.4796e-01, 8.6065e-01, 9.1454e-02,\n",
       "        4.8072e-01, 5.8918e-01, 9.7819e-01, 3.2934e-01, 6.3729e-01, 7.9186e-02,\n",
       "        7.1330e-01, 2.9916e-01, 5.9594e-01, 2.6797e-02, 5.7423e-01, 5.3059e-01,\n",
       "        8.4476e-02, 7.3567e-01, 2.4545e-01, 3.0048e-01, 8.0973e-01, 3.8890e-01,\n",
       "        1.8193e-01, 7.2243e-01, 8.8500e-01, 7.3851e-01, 8.0035e-01, 1.3752e-01,\n",
       "        4.5697e-01, 2.6594e-01, 6.2719e-01, 1.0944e-02, 2.9947e-01, 6.1002e-01,\n",
       "        2.2812e-01, 6.4592e-01, 9.2459e-01, 2.9888e-01, 4.6379e-01, 2.6842e-01,\n",
       "        8.4523e-01, 2.4177e-01, 7.0712e-01, 3.1998e-01, 9.3988e-01, 7.1249e-01,\n",
       "        8.4657e-01, 3.4863e-01, 3.7256e-01, 8.6740e-01, 8.9179e-01, 9.6078e-01,\n",
       "        4.5771e-01, 4.4446e-01, 7.2708e-01, 9.0747e-01, 5.1347e-01, 3.7849e-01,\n",
       "        4.1044e-01, 8.8010e-01, 4.9726e-01, 7.1575e-01, 9.6664e-01, 4.7793e-01,\n",
       "        6.5341e-01, 1.2532e-01, 3.7409e-02, 6.8809e-01, 3.2446e-01, 2.1484e-01,\n",
       "        4.5565e-01, 5.6412e-01, 3.1338e-01, 6.2194e-01, 7.7783e-01, 3.0437e-01,\n",
       "        9.3138e-01, 4.1656e-01, 4.3162e-01, 3.5517e-01, 6.0018e-01, 3.9193e-01,\n",
       "        1.3831e-01, 5.1753e-01, 5.9920e-01, 4.9435e-01, 9.6341e-01, 5.0953e-01,\n",
       "        6.8693e-01, 6.2878e-01, 2.1659e-01, 9.4617e-01, 4.9512e-01, 2.1599e-01,\n",
       "        5.2510e-01, 7.9693e-01, 6.6689e-01, 6.0672e-01, 5.9192e-03, 6.5411e-01,\n",
       "        2.5494e-01, 6.9592e-01, 6.2919e-01, 1.4690e-01, 5.2077e-02, 8.8507e-01,\n",
       "        3.9233e-01, 1.1977e-01, 8.1310e-01, 9.0628e-01, 8.6977e-01, 2.2128e-01,\n",
       "        2.7469e-02, 5.8687e-01, 7.3165e-01, 5.8193e-01, 8.5885e-01, 2.7555e-01,\n",
       "        4.1960e-01, 7.0422e-01, 4.1373e-01, 6.3654e-01, 2.0513e-01, 4.0350e-01,\n",
       "        7.9094e-01, 7.4844e-01, 6.6148e-01, 3.9167e-01, 5.9262e-01, 9.9971e-01,\n",
       "        7.5896e-01, 4.4037e-01, 9.2064e-01, 7.9794e-01, 8.1249e-01, 4.7599e-01,\n",
       "        2.9287e-01, 9.4105e-01, 2.1816e-01, 4.3081e-01, 6.7431e-01, 8.3128e-01])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeated_tensor[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d411944d-a5eb-4e62-ab1b-f7266f7c7f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
